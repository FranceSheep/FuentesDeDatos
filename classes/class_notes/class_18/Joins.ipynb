{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joins\n",
    "---------\n",
    "The material in this notebook was extracted from\n",
    "* Spark The Definitive Guide Big Data Processing Made Simple (2018)\n",
    "---------\n",
    "\n",
    "A join brings together two sets of data, the left and the right, by comparing the value of one or more *keys*: if they are equal, Spark will combine the left and right datasets. The opposite is true for keys that do not match; Spark discards the rows that do not have matching keys. \n",
    "\n",
    "##### Join Types\n",
    "\n",
    "Whereas the join expression determines whether two rows should join, the join type determines what should be in the result set. There are various join types available in Spark:\n",
    "\n",
    "* Inner joins (keep rows with keys that exist in the left and right datasets)\n",
    "* Outer joins (keep rows with keys in either the left or right datasets)\n",
    "* Left semi joins (keep the rows of the left dataset where the key appears in the right dataset)\n",
    "* Left anti joins (keep the rows of the left dataset where the key doesn't appear in the right dataset)\n",
    "* Natural joins (perform a join by implicitly matching the columns between the two datasets with the same names)\n",
    "* Cross joins (match every row in the left dataset with every row in the right dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "person = spark.createDataFrame([\n",
    "    (0, \"Bill Chambers\", 0, [100]),\n",
    "    (1, \"Matel Zaharia\", 1, [500, 250, 100]),\n",
    "    (2, \"Michael Armbrust\", 1, [250, 100]),\n",
    "    (3, \"Luis\", 4, [250, 100, 1000])\n",
    "]).toDF(\"id\", \"name\", \"graduate_program\", \"spark_status\")\n",
    "program = spark.createDataFrame([\n",
    "    (0, \"Masters\", \"School of Information\", \"UC Berkley\"),\n",
    "    (1, \"Masters\", \"EECS\", \"UC Berkley\"),\n",
    "    (2, \"Ph.D.\", \"EECS\", \"UC Berkley\")\n",
    "]).toDF(\"id\", \"degree\", \"department\", \"school\")\n",
    "status = spark.createDataFrame([\n",
    "    (500, \"Vice President\"),\n",
    "    (250, \"PMC Member\"),\n",
    "    (100, \"Contributor\"),\n",
    "    (1000, \"CEO\")\n",
    "]).toDF(\"id\", \"status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inner Joins\n",
    "\n",
    "Inner joins evaluate keys in both DataFrames and include only the rows that evaluate to true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "joinCondition = person['graduate_program'] == program['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                (0 + 12) / 12][Stage 1:>                 (0 + 0) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+----------------+---------------+---+-------+--------------------+----------+\n",
      "| id|            name|graduate_program|   spark_status| id| degree|          department|    school|\n",
      "+---+----------------+----------------+---------------+---+-------+--------------------+----------+\n",
      "|  0|   Bill Chambers|               0|          [100]|  0|Masters|School of Informa...|UC Berkley|\n",
      "|  1|   Matel Zaharia|               1|[500, 250, 100]|  1|Masters|                EECS|UC Berkley|\n",
      "|  2|Michael Armbrust|               1|     [250, 100]|  1|Masters|                EECS|UC Berkley|\n",
      "+---+----------------+----------------+---------------+---+-------+--------------------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "person.join(program, joinCondition).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or more explicitly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+----------------+---------------+---+-------+--------------------+----------+\n",
      "| id|            name|graduate_program|   spark_status| id| degree|          department|    school|\n",
      "+---+----------------+----------------+---------------+---+-------+--------------------+----------+\n",
      "|  0|   Bill Chambers|               0|          [100]|  0|Masters|School of Informa...|UC Berkley|\n",
      "|  1|   Matel Zaharia|               1|[500, 250, 100]|  1|Masters|                EECS|UC Berkley|\n",
      "|  2|Michael Armbrust|               1|     [250, 100]|  1|Masters|                EECS|UC Berkley|\n",
      "+---+----------------+----------------+---------------+---+-------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "person.join(program, \n",
    "            person['graduate_program'] == program['id'], \n",
    "            'inner').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Outer Joins\n",
    "\n",
    "Outer joins evaluate the keys in both of the DataFrames and includes the rows that evaluate true or false. If there is no eequivalent row in either left or right DataFrame, Spark will insert null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+----------------+----------------+----+-------+--------------------+----------+\n",
      "| id|            name|graduate_program|    spark_status|  id| degree|          department|    school|\n",
      "+---+----------------+----------------+----------------+----+-------+--------------------+----------+\n",
      "|  0|   Bill Chambers|               0|           [100]|   0|Masters|School of Informa...|UC Berkley|\n",
      "|  1|   Matel Zaharia|               1| [500, 250, 100]|   1|Masters|                EECS|UC Berkley|\n",
      "|  2|Michael Armbrust|               1|      [250, 100]|   1|Masters|                EECS|UC Berkley|\n",
      "|  3|            Luis|               4|[250, 100, 1000]|null|   null|                null|      null|\n",
      "+---+----------------+----------------+----------------+----+-------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "person.join(program, \n",
    "            person['graduate_program'] == program['id'], \n",
    "            'left_outer').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------------+----------+\n",
      "| id| degree|          department|    school|\n",
      "+---+-------+--------------------+----------+\n",
      "|  0|Masters|School of Informa...|UC Berkley|\n",
      "|  1|Masters|                EECS|UC Berkley|\n",
      "|  2|  Ph.D.|                EECS|UC Berkley|\n",
      "+---+-------+--------------------+----------+\n",
      "\n",
      "+---+----------------+----------------+----------------+\n",
      "| id|            name|graduate_program|    spark_status|\n",
      "+---+----------------+----------------+----------------+\n",
      "|  0|   Bill Chambers|               0|           [100]|\n",
      "|  1|   Matel Zaharia|               1| [500, 250, 100]|\n",
      "|  2|Michael Armbrust|               1|      [250, 100]|\n",
      "|  3|            Luis|               4|[250, 100, 1000]|\n",
      "+---+----------------+----------------+----------------+\n",
      "\n",
      "+---+----------------+----------------+---------------+\n",
      "| id|            name|graduate_program|   spark_status|\n",
      "+---+----------------+----------------+---------------+\n",
      "|  0|   Bill Chambers|               0|          [100]|\n",
      "|  1|   Matel Zaharia|               1|[500, 250, 100]|\n",
      "|  2|Michael Armbrust|               1|     [250, 100]|\n",
      "+---+----------------+----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "program.show()\n",
    "person.show()\n",
    "person.join(program, \n",
    "            person['graduate_program'] == program['id'], \n",
    "            'left_semi').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------+----------------+---------------+---+-------+--------------------+----------+\n",
      "|  id|            name|graduate_program|   spark_status| id| degree|          department|    school|\n",
      "+----+----------------+----------------+---------------+---+-------+--------------------+----------+\n",
      "|   0|   Bill Chambers|               0|          [100]|  0|Masters|School of Informa...|UC Berkley|\n",
      "|   1|   Matel Zaharia|               1|[500, 250, 100]|  1|Masters|                EECS|UC Berkley|\n",
      "|   2|Michael Armbrust|               1|     [250, 100]|  1|Masters|                EECS|UC Berkley|\n",
      "|null|            null|            null|           null|  2|  Ph.D.|                EECS|UC Berkley|\n",
      "+----+----------------+----------------+---------------+---+-------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "person.join(program, \n",
    "            person['graduate_program'] == program['id'], \n",
    "            'right_outer').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Left Semi Joins\n",
    "\n",
    "They do not actually include any values from the right DataFrame. If the value does exist, those rows will be kept in the result, even if there are duplicate keys in the left DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------------+----------+\n",
      "| id| degree|          department|    school|\n",
      "+---+-------+--------------------+----------+\n",
      "|  0|Masters|School of Informa...|UC Berkley|\n",
      "|  1|Masters|                EECS|UC Berkley|\n",
      "+---+-------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "program.join(person, \n",
    "            person['graduate_program'] == program['id'], \n",
    "            'left_semi').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+----------------+---------------+\n",
      "| id|            name|graduate_program|   spark_status|\n",
      "+---+----------------+----------------+---------------+\n",
      "|  0|   Bill Chambers|               0|          [100]|\n",
      "|  1|   Matel Zaharia|               1|[500, 250, 100]|\n",
      "|  2|Michael Armbrust|               1|     [250, 100]|\n",
      "+---+----------------+----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "person.join(program, \n",
    "           person['graduate_program'] == program['id'],\n",
    "           'left_semi').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Left Anti Joins\n",
    "\n",
    "Left anti joins are the opposite of left semi joins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------+----------+\n",
      "| id|degree|department|    school|\n",
      "+---+------+----------+----------+\n",
      "|  2| Ph.D.|      EECS|UC Berkley|\n",
      "+---+------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "program.join(person, \n",
    "            person['graduate_program'] == program['id'], \n",
    "            'left_anti').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Joins on Complex Types\n",
    "\n",
    "Any expression is a valid join expression, assuming it returns a Boolean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+----------------+----+--------------+\n",
      "|personId|            name|    spark_status|  id|        status|\n",
      "+--------+----------------+----------------+----+--------------+\n",
      "|       0|   Bill Chambers|           [100]| 100|   Contributor|\n",
      "|       1|   Matel Zaharia| [500, 250, 100]| 500|Vice President|\n",
      "|       1|   Matel Zaharia| [500, 250, 100]| 250|    PMC Member|\n",
      "|       1|   Matel Zaharia| [500, 250, 100]| 100|   Contributor|\n",
      "|       2|Michael Armbrust|      [250, 100]| 250|    PMC Member|\n",
      "|       2|Michael Armbrust|      [250, 100]| 100|   Contributor|\n",
      "|       3|            Luis|[250, 100, 1000]| 250|    PMC Member|\n",
      "|       3|            Luis|[250, 100, 1000]| 100|   Contributor|\n",
      "|       3|            Luis|[250, 100, 1000]|1000|           CEO|\n",
      "+--------+----------------+----------------+----+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "person.selectExpr('id as personId', 'name', 'spark_status')\\\n",
    ".join(status, expr('array_contains(spark_status, id)')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "DATA_PATH = './data/'\n",
    "movies_df = spark.read.csv(DATA_PATH + 'movies.csv', \n",
    "                           inferSchema=True, \n",
    "                           header=True, \n",
    "                           sep=',')\n",
    "ratings_df = spark.read.csv(DATA_PATH + 'ratings.csv',\n",
    "                           inferSchema=True,\n",
    "                           header=True,\n",
    "                           sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------+-------+-----------------------------------------+\n",
      "|title                                    |movieId|genres                                   |\n",
      "+-----------------------------------------+-------+-----------------------------------------+\n",
      "|Heat (1995)                              |6      |[Action, Crime, Thriller]                |\n",
      "|GoldenEye (1995)                         |10     |[Action, Adventure, Thriller]            |\n",
      "|Dracula: Dead and Loving It (1995)       |12     |[Comedy, Horror]                         |\n",
      "|Money Train (1995)                       |20     |[Action, Comedy, Crime, Drama, Thriller] |\n",
      "|Get Shorty (1995)                        |21     |[Comedy, Crime, Thriller]                |\n",
      "|Copycat (1995)                           |22     |[Crime, Drama, Horror, Mystery, Thriller]|\n",
      "|Assassins (1995)                         |23     |[Action, Crime, Thriller]                |\n",
      "|Twelve Monkeys (a.k.a. 12 Monkeys) (1995)|32     |[Mystery, Sci-Fi, Thriller]              |\n",
      "|To Die For (1995)                        |45     |[Comedy, Drama, Thriller]                |\n",
      "|Seven (a.k.a. Se7en) (1995)              |47     |[Mystery, Thriller]                      |\n",
      "+-----------------------------------------+-------+-----------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 59:======================================>                  (8 + 4) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+------------------+\n",
      "|movieId|count|       mean_rating|\n",
      "+-------+-----+------------------+\n",
      "|   1645|14346| 3.516589990241182|\n",
      "|   1591| 6317|2.6416020262782967|\n",
      "|   2122| 2825| 2.634513274336283|\n",
      "|   3918| 1447|2.9595715272978578|\n",
      "|   2366| 8162|3.4740872335211956|\n",
      "|   1342| 3881|2.9637979902087093|\n",
      "|   5300|  619| 3.608239095315024|\n",
      "|   7982|  870| 3.607471264367816|\n",
      "|   7993|  104|3.2788461538461537|\n",
      "|  57370|  181|  2.81767955801105|\n",
      "|    496|  423|3.2919621749408985|\n",
      "|  31367|  207| 2.893719806763285|\n",
      "| 166558|  205|3.0682926829268293|\n",
      "|    463|  428|2.8119158878504673|\n",
      "|   1127|19010| 3.666859547606523|\n",
      "|  48780|20276| 4.078294535411324|\n",
      "|  69481| 7319|3.7412214783440363|\n",
      "|   1483| 3229| 3.121554660885723|\n",
      "|    540| 5305|2.7241281809613573|\n",
      "|  74452|  613|2.6557911908646004|\n",
      "+-------+-----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "# Clean movies\n",
    "clean_movies = movies_df.select('title', 'movieId',  \n",
    "                 F.split(F.col('genres'), '\\|')\\\n",
    "                .alias('genres'))\\\n",
    ".filter(F.array_contains(F.col('genres'), 'Horror') | \n",
    "        F.array_contains(F.col('genres'), 'Thriller'))\n",
    "clean_movies.show(10, False)\n",
    "# Join with ratings\n",
    "rating_stats = ratings_df.groupBy(F.col('movieId'))\\\n",
    ".agg(F.count('*').alias('count'), \n",
    "     F.avg('rating').alias('mean_rating'))\\\n",
    ".filter(F.col('count') > 100)\\\n",
    ".join(clean_movies, on='movieId', how='left_semi')\n",
    "rating_stats.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
